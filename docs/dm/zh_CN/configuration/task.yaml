---
name: test # global unique
task-mode: all  # full/incremental/all
is-sharding: true  # whether multi dm-worker do one sharding job
meta-schema: "dm_meta"  # meta schema in downstreaming database to store meta informaton of dm
remove-meta: false  # remove meta from downstreaming database, now we delete checkpoint and online ddl information
enable-heartbeat: false  # whether to enable heartbeat for calculating lag between master and syncer
# timezone: "Asia/Shanghai" # target database timezone, all timestamp event in binlog will translate to format time based on this timezone, default use DM-worker node's local timezone

target-database:
  host: "192.168.0.1"
  port: 4000
  user: "root"
  password: ""

mysql-instances:             # one or more source database, config more source database for sharding merge
  -
    source-id: "mysql-replica-01" # unique in all instances

    # binlog pos used to as start pos for syncer, for different task-mode, this maybe used or not
    # `full` / `all`:
    #    never be used
    # `incremental`:
    #    if `remove-meta` is true, this will be used
    #    else if checkpoints already exists in `meta-schema`, this will not be used
    #    otherwise, this will be used
    meta:
      binlog-name: binlog-00001
      binlog-pos: 4
    route-rules: ["route-rule-1", "route-rule-2"]
    filter-rules: ["user-filter-1", "user-filter-2"]
    column-mapping-rules: ["cm-rule-1"]
    black-white-list:  "bw-rule-1"


    mydumper-config-name: "global"   # ref `mydumpers` config
    loader-config-name: "global"     # ref `loaders` config
    syncer-config-name: "global"     # ref `syncers` config

  -
    source-id: "mysql-replica-02"
    meta:
      binlog-name: binlog-00001
      binlog-pos: 320
   route-rules: ["route-rule-1", "route-rule-2"]
    filter-rules: ["user-filter-2"]
    column-mapping-rules: ["cm-rule-2"]
    black-white-list:  "bw-rule-1"

    mydumper-config-name: "global"   # ref `mydumpers` config
    loader-config-name: "global"     # ref `loaders` config
    syncer-config-name: "global"     # ref `syncers` config

# other common configs shared by all instances

routes:                      # schema/table route mapping
  route-rule-1:
    schema-pattern: "test_*"
    target-schema: "test"
  route-rule-2:
    schema-pattern: "test_*"
    table-pattern: "t_*"
    target-schema: "test"
    target-table: "t"

filters:                     # filter rules, mysql instance can ref rules in it
  user-filter-1:
    schema-pattern: "test_*"
    table-pattern: "t_*"
    events: ["truncate table", "drop table"]  # ignore truncate/drop table ddl
    action: Ignore
  user-filter-2:
    schema-pattern: "test_*"
    events: ["All DML"]             # only do all DML events
    action: Do

black-white-list:
  bw-rule-1:
    do-dbs: ["~^test.*", "do"]
    ignore-dbs: ["mysql", "ignored"]
    do-tables:
    - db-name: "~^test.*"
      tbl-name: "~^t.*"
    - db-name: "do"
      tbl-name: "do"
    - db-name: "do"
      tbl-name: "do"


column-mappings:             # column mapping rules, mysql instance can ref rules in it
  cm-rule-1:
    schema-pattern: "test_*"
    table-pattern: "t_*"
    expression: "partition id"       # handle sharding partition id
    source-column: "id"
    target-column: "id"
    arguments: ["1", "test_", "t_"]
  cm-rule-2:
    schema-pattern: "test_*"
    table-pattern: "t_*"
    expression: "partition id"       # handle sharding partition id
    source-column: "id"
    target-column: "id"
    arguments: ["2", "test_", "t_"]

mydumpers:                   # mydumper process unit specific configs, mysql instance can ref one config in it
  global:
    mydumper-path: "./bin/mydumper"
    threads: 4
    chunk-filesize: 64
    skip-tz-utc: true
    extra-args: "-B test -T t1,t2 --no-locks"

loaders:                     # loader process unit specific configs, mysql instance can ref one config in it
  global:
    pool-size: 16
    dir: "./dumped_data"

syncers:                     # syncer process unit specific configs, mysql instance can ref one config in it
  global:
    worker-count: 16
    batch: 100
    max-retry: 100